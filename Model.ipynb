{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1835cc1-4b29-4abe-b750-f91d032e0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8125de3b-a43f-4e28-afc4-36f574491741",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeder = utils.PhotoEmbedingStorage('emb storage.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd9bf25-bb9c-41b2-9cd7-5c47d7291b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity tensor([[0.7698]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeder[13550]\n",
    "emb2 = embeder[2169]\n",
    "print('similarity', emb1 @ emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0579a5-4e1d-42eb-bdf5-1ad10d832e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity tensor([[0.6263]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeder[13543]\n",
    "emb2 = embeder[13544]\n",
    "print('similarity', emb1 @ emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9f9363-5555-4583-921c-eb049330f442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity tensor([[0.5527]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeder[13546]\n",
    "emb2 = embeder[13547]\n",
    "print('similarity', emb1 @ emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7615d610-e5e1-4102-9c8e-96bf36da4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity tensor([[0.3056]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeder[13543]\n",
    "emb2 = embeder[13550]\n",
    "print('similarity', emb1 @ emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7e978a-cfbd-45f9-91fc-783851acb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EMBED_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1423991-60e5-43b1-9dc9-8d812d336c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d58d66-f2b2-4c55-a9ba-88a3c0308560",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_opposite = []\n",
    "files_target = []\n",
    "\n",
    "path = \"data/markup_opposite/\"\n",
    "files_opposite += [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "    \n",
    "path =  \"data/markup_target/\"\n",
    "files_target += [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "\n",
    "path = \"data/opposite/\"\n",
    "files_opposite += [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "\n",
    "path =  \"data/target/\"\n",
    "files_target += [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "\n",
    "files_opposite = np.array(files_opposite)\n",
    "files_target = np.array(files_target)\n",
    "\n",
    "y_opposite = np.zeros_like(files_opposite, dtype='float32')\n",
    "y_target = np.ones_like(files_target, dtype='float32')\n",
    "\n",
    "X = np.concatenate([files_opposite, files_target])\n",
    "Y = np.concatenate([y_opposite, y_target])\n",
    "\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba82b8d1-6db5-43e9-96bf-66ffb9eb29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = []\n",
    "Ytest = []\n",
    "\n",
    "path = \"data/test_target/\"\n",
    "ldir = [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "Xtest+= ldir\n",
    "Ytest+= [1. for _ in ldir]\n",
    "    \n",
    "path = \"data/test_opposite/\"\n",
    "ldir = [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "Xtest+= ldir\n",
    "Ytest+= [0. for _ in ldir]\n",
    "\n",
    "Xtest = np.array(Xtest)\n",
    "Ytest = np.array(Ytest, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbb0ef22-08d5-4ee7-a39d-2db39507c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.concatenate([embeder[int(xid)] for xid in Xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55c3939b-136d-4f31-a6f4-c1540645c433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=32)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=EMBED_DIM)\n",
    "pca.fit(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08ec1aa5-7622-4f86-9dd4-5b20e7699d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca, open(\"models/pca.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad102a4a-9397-43a2-b284-10fe872ff4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedDataset(Dataset):\n",
    "    def __init__(self, x, y, embeder,\n",
    "                 decompositor=None,\n",
    "                 **kwargs):\n",
    "        assert len(x) == len(y)\n",
    "        \n",
    "        self.embeder = embeder\n",
    "        self.x_opposite = x[y == 0.]\n",
    "        self.x_target = x[y == 1.]\n",
    "        self.y_opposite = y[y == 0.]\n",
    "        self.y_target = y[y == 1.]\n",
    "        self.decompositor = decompositor\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_opposite) + len(self.y_target)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, _):\n",
    "        if random.random() > 0.5:\n",
    "            target = False\n",
    "            idx = random.choice(range(len(self.x_opposite)))\n",
    "            xid, y = self.x_opposite[idx], self.y_opposite[idx]\n",
    "            \n",
    "        else:\n",
    "            target = True\n",
    "            idx = random.choice(range(len(self.x_target)))\n",
    "            xid, y = self.x_target[idx], self.y_target[idx]\n",
    "            \n",
    "            \n",
    "        x = self.embeder[int(xid)]\n",
    "        if self.decompositor:\n",
    "            x = self.decompositor(x).astype('float32')\n",
    "        \n",
    "        return x[0], y[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "327c59c2-cfd9-4227-bb94-5869478de933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, x, y, embeder,\n",
    "                 decompositor=None,\n",
    "                 **kwargs):\n",
    "        assert len(x) == len(y)\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        self.embeder = embeder\n",
    "        self.decompositor = decompositor\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.y[idx]\n",
    "        x = self.embeder[int(self.x[idx])]\n",
    "        \n",
    "        if self.decompositor:\n",
    "            x = self.decompositor(x).astype('float32')\n",
    "            \n",
    "        return x[0], y[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "847a6751-ab68-4fd7-b248-05d60eede041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, d=[32, 32], **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        seq = []\n",
    "        d = [input_dim] + d + [1]\n",
    "        for i in range(len(d)-1):\n",
    "            seq.append(\n",
    "                nn.Linear(d[i], d[i+1])\n",
    "            )\n",
    "            seq.append(nn.Dropout(p=0.5))\n",
    "            if i != len(d)-2:\n",
    "                seq.append(nn.GELU())\n",
    "                \n",
    "        self.seq = nn.Sequential(*seq)\n",
    "\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d810e6b-aa98-45b7-8fc6-a73a50bebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, \n",
    "        model, loss_fn, optimizer, \n",
    "        stop_batch, metric=None,\n",
    "        device='cuda', fp16=False, \n",
    "        **kwargs):\n",
    "        self.model: nn.Module = model\n",
    "        self.device = device\n",
    "        self.metric = metric\n",
    "        \n",
    "        self.stop_batch = stop_batch\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer  \n",
    "        \n",
    "        self.fp16 = fp16\n",
    "        if fp16:\n",
    "            self.scaler = torch.cuda.amp.GradScaler()        \n",
    "        \n",
    "        \n",
    "    def checkpoint(self) -> dict:\n",
    "        cpoint =  {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"optimizer\": self.optimizer.state_dict(),\n",
    "        }\n",
    "        if self.fp16:\n",
    "            cpoint[\"scaler\"] = self.scaler.state_dict()\n",
    "            \n",
    "        return cpoint\n",
    "    \n",
    "        \n",
    "    def train(self, dataset, epoch) -> float:\n",
    "        self.model.train()\n",
    "        running_loss = 0\n",
    "        for idx, batch in enumerate(dataset):\n",
    "            X, Y = batch\n",
    "            X, Y = X.to(self.device), Y.to(self.device)\n",
    "            running_loss+= self.__train(X, Y)\n",
    "            if idx >= self.stop_batch:\n",
    "                break\n",
    "                \n",
    "        return running_loss\n",
    "            \n",
    "            \n",
    "    def val(self, dataset) -> list[torch.Tensor]:\n",
    "        self.model.eval()\n",
    "        val_pred, val_true = [], []\n",
    "        with torch.inference_mode():\n",
    "            for batch in dataset:\n",
    "                X, Y = batch\n",
    "                val_pred+= [self.model(X.to(self.device)).cpu()]\n",
    "                val_true+= [Y]\n",
    "        return torch.cat(val_pred), torch.cat(val_true)\n",
    "                \n",
    "            \n",
    "    def __train(self, X, Y) -> float:\n",
    "        self.optimizer.zero_grad()\n",
    "        if self.fp16:\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                outputs = self.model(X)\n",
    "                loss = self.loss_fn(outputs, Y)\n",
    "                \n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "\n",
    "        else:\n",
    "            outputs = self.model(X)\n",
    "            loss = self.loss_fn(outputs, Y)    \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        if self.metric:\n",
    "            self.metric(outputs.sigmoid(), Y.int())\n",
    "            \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb8a6bfe-3f63-4fcb-9bc9-41f3efa2cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    EmbedDataset(\n",
    "        x=Xtrain, \n",
    "        y=Ytrain, \n",
    "        embeder=embeder,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2565cb2-f3b2-460b-851e-dd0bd9a9ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valLoader = torch.utils.data.DataLoader(\n",
    "    TestDataset(\n",
    "        x=Xval, \n",
    "        y=Yval, \n",
    "        embeder=embeder,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "643c68e6-f9c7-4a97-879b-62e887a85829",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoader = torch.utils.data.DataLoader(\n",
    "    TestDataset(\n",
    "        x=Xtest, \n",
    "        y=Ytest, \n",
    "        embeder=embeder,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff882e6c-a0e5-4819-b296-46b750f52bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = Model(EMBED_DIM, d=[64, 64])\n",
    "trainer = Trainer(\n",
    "    model=model.cuda(),\n",
    "    stop_batch=10_000/2048,\n",
    "    metric=torchmetrics.AUROC(),\n",
    "    loss_fn=nn.BCEWithLogitsLoss(reduce=True),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=3e-4),\n",
    ")\n",
    "\n",
    "acc = torchmetrics.Accuracy()\n",
    "auc = torchmetrics.AUROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47a23061-f7d0-4005-9a1c-6a9eac47c6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Linear: 2-1                       2,112\n",
      "|    └─Dropout: 2-2                      --\n",
      "|    └─GELU: 2-3                         --\n",
      "|    └─Linear: 2-4                       2,080\n",
      "|    └─Dropout: 2-5                      --\n",
      "|    └─GELU: 2-6                         --\n",
      "|    └─Linear: 2-7                       33\n",
      "|    └─Dropout: 2-8                      --\n",
      "=================================================================\n",
      "Total params: 4,225\n",
      "Trainable params: 4,225\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "022ec494-041d-4974-82bb-21e498a9f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'InceptionResnetV1 vggface2 pca 64'\n",
    "board_name = name + datetime.datetime.now().strftime(\"%Y.%m.%d - %H-%M-%S\")\n",
    "\n",
    "log_dir = f\"logs/fit/{board_name}\"\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e29411c-1ad0-4713-92a8-a118a7c5d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wait = 0\n",
    "    patience = 50\n",
    "    \n",
    "    epoch = 0\n",
    "    best_loss = -np.inf\n",
    "    while wait < patience:\n",
    "        train_loss = trainer.train(trainLoader, epoch)\n",
    "\n",
    "        val_pred, val_true = trainer.val(valLoader)\n",
    "        metrics = {\n",
    "            'AUC': auc(val_pred.sigmoid(), val_true.int()),\n",
    "            'ACC': acc(val_pred.sigmoid(), val_true.int()),\n",
    "        }\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('AUC/train', trainer.metric.compute(), epoch)\n",
    "        writer.add_scalar('AUC/val', metrics['AUC'], epoch)\n",
    "        writer.add_scalar('ACC/val', metrics['ACC'], epoch)\n",
    "\n",
    "\n",
    "        wait+=1\n",
    "        epoch+=1\n",
    "        if metrics['AUC'] > best_loss:\n",
    "            checkpoint = trainer.checkpoint()\n",
    "            torch.save(checkpoint, f'models/w/{name}.torch')\n",
    "            best_loss = metrics['AUC']\n",
    "            wait = 0\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22688115-7a71-40df-8250-9bd50edb57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'models/w/{name}.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f30a6965-c063-4421-9329-b0b09796743a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00dae26d-de34-4442-8598-48ccb0ffc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred, test_true = trainer.val(testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d4ca4f7-6fe2-4aeb-bfc1-2b4fde55f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: tensor(0.7045)\n",
      "ACC: tensor(0.8362)\n"
     ]
    }
   ],
   "source": [
    "print('AUC:', auc(val_pred.sigmoid(), val_true.int()))\n",
    "print('ACC:', acc(val_pred.sigmoid(), val_true.int()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
