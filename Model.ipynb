{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1835cc1-4b29-4abe-b750-f91d032e0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9c7e978a-cfbd-45f9-91fc-783851acb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EMBED_DIM = 32\n",
    "\n",
    "mtcnn = MTCNN()\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "90f5c47f-ab78-4c39-9161-bb6cc3cd58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn.thresholds = [0., 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c0d58d66-f2b2-4c55-a9ba-88a3c0308560",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_opposite = []\n",
    "files_target = []\n",
    "\n",
    "path = DATASET_PATH + \"/markup_opposite/\"\n",
    "files_opposite += [path + f for f in os.listdir(path)]\n",
    "    \n",
    "path = DATASET_PATH + \"/markup_target/\"\n",
    "files_target += [path + f for f in os.listdir(path)]\n",
    "\n",
    "path = DATASET_PATH + \"/opposite/\"\n",
    "files_opposite += [path + f for f in os.listdir(path)]\n",
    "\n",
    "path = DATASET_PATH + \"/target/\"\n",
    "files_target += [path + f for f in os.listdir(path)]\n",
    "\n",
    "files_opposite = np.array(files_opposite)\n",
    "files_target = np.array(files_target)\n",
    "\n",
    "y_opposite = np.zeros_like(files_opposite, dtype='float32')\n",
    "y_target = np.ones_like(files_target, dtype='float32')\n",
    "\n",
    "X = np.concatenate([files_opposite, files_target])\n",
    "Y = np.concatenate([y_opposite, y_target])\n",
    "\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ba82b8d1-6db5-43e9-96bf-66ffb9eb29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = []\n",
    "Ytest = []\n",
    "\n",
    "path = DATASET_PATH + \"/test_target/\"\n",
    "ldir = [path + f for f in os.listdir(path)]\n",
    "Xtest+= ldir\n",
    "Ytest+= [1. for _ in ldir]\n",
    "    \n",
    "path = DATASET_PATH + \"/test_opposite/\"\n",
    "ldir = [path + f for f in os.listdir(path)]\n",
    "Xtest+= ldir\n",
    "Ytest+= [1. for _ in ldir]\n",
    "\n",
    "Xtest = np.array(Xtest)\n",
    "Ytest = np.array(Ytest, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d43568f8-1d80-44cc-a47f-0bcfe9e3a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xembs = {}\n",
    "# with torch.no_grad():\n",
    "#     for _x in [Xtrain, Xval, Xtest]:\n",
    "#         for x_path in _x:\n",
    "#             img = Image.open(x_path)\n",
    "#             img = mtcnn(img)\n",
    "#             Xembs[x_path] = resnet(img.unsqueeze(0)).numpy()\n",
    "            \n",
    "# torch.save(Xembs, 'InceptionResnetV1_vggface2.dict')\n",
    "# Xembs = torch.load('InceptionResnetV1_vggface2.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bbb0ef22-08d5-4ee7-a39d-2db39507c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.concatenate([Xembs[x_path] for x_path in Xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "55c3939b-136d-4f31-a6f4-c1540645c433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=32)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=EMBED_DIM)\n",
    "pca.fit(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ad102a4a-9397-43a2-b284-10fe872ff4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedDataset(Dataset):\n",
    "    def __init__(self, x, y, embeds,\n",
    "                 decompositor=None,\n",
    "                 **kwargs):\n",
    "        assert len(x) == len(y)\n",
    "        \n",
    "        self.embeds = embeds\n",
    "        self.x_opposite = x[y == 0.]\n",
    "        self.x_target = x[y == 1.]\n",
    "        self.y_opposite = y[y == 0.]\n",
    "        self.y_target = y[y == 1.]\n",
    "    \n",
    "        self.decompositor = decompositor\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_opposite) + len(self.y_target)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, _):\n",
    "        if random.random() > 0.5:\n",
    "            target = False\n",
    "            idx = random.choice(range(len(self.x_opposite)))\n",
    "            x_path, y = self.x_opposite[idx], self.y_opposite[idx]\n",
    "            \n",
    "        else:\n",
    "            target = True\n",
    "            idx = random.choice(range(len(self.x_target)))\n",
    "            x_path, y = self.x_target[idx], self.y_target[idx]\n",
    "            \n",
    "            \n",
    "        x = self.embeds[x_path]\n",
    "        if self.decompositor:\n",
    "            x = self.decompositor(x).astype('float32')\n",
    "        \n",
    "        return x[0], y[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "327c59c2-cfd9-4227-bb94-5869478de933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, x, y, embeds,\n",
    "                 decompositor=None,\n",
    "                 **kwargs):\n",
    "        assert len(x) == len(y)\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        self.embeds = embeds\n",
    "        self.decompositor = decompositor\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.y[idx]\n",
    "        x = self.embeds[self.x[idx]]\n",
    "        \n",
    "        if self.decompositor:\n",
    "            x = self.decompositor(x).astype('float32')\n",
    "            \n",
    "        return x[0], y[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "847a6751-ab68-4fd7-b248-05d60eede041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, d=[32, 32], **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        seq = []\n",
    "        d = [input_dim] + d + [1]\n",
    "        for i in range(len(d)-1):\n",
    "            seq.append(\n",
    "                nn.Linear(d[i], d[i+1])\n",
    "            )\n",
    "            seq.append(nn.Dropout(p=0.5))\n",
    "            if i != len(d)-2:\n",
    "                seq.append(nn.GELU())\n",
    "                \n",
    "        self.seq = nn.Sequential(*seq)\n",
    "\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9d810e6b-aa98-45b7-8fc6-a73a50bebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, \n",
    "        model, loss_fn, optimizer, \n",
    "        stop_batch, metric=None,\n",
    "        device='cuda', fp16=False, \n",
    "        **kwargs):\n",
    "        self.model: nn.Module = model\n",
    "        self.device = device\n",
    "        self.metric = metric\n",
    "        \n",
    "        self.stop_batch = stop_batch\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer  \n",
    "        \n",
    "        self.fp16 = fp16\n",
    "        if fp16:\n",
    "            self.scaler = torch.cuda.amp.GradScaler()        \n",
    "        \n",
    "        \n",
    "    def checkpoint(self) -> dict:\n",
    "        cpoint =  {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"optimizer\": self.optimizer.state_dict(),\n",
    "        }\n",
    "        if self.fp16:\n",
    "            cpoint[\"scaler\"] = self.scaler.state_dict()\n",
    "            \n",
    "        return cpoint\n",
    "    \n",
    "        \n",
    "    def train(self, dataset, epoch) -> float:\n",
    "        self.model.train()\n",
    "        running_loss = 0\n",
    "        for idx, batch in enumerate(dataset):\n",
    "            X, Y = batch\n",
    "            X, Y = X.to(self.device), Y.to(self.device)\n",
    "            running_loss+= self.__train(X, Y)\n",
    "            if idx >= self.stop_batch:\n",
    "                break\n",
    "                \n",
    "        return running_loss\n",
    "            \n",
    "            \n",
    "    def val(self, dataset) -> list[torch.Tensor]:\n",
    "        self.model.eval()\n",
    "        val_pred, val_true = [], []\n",
    "        with torch.inference_mode():\n",
    "            for batch in dataset:\n",
    "                X, Y = batch\n",
    "                val_pred+= [self.model(X.to(self.device)).cpu()]\n",
    "                val_true+= [Y]\n",
    "        return torch.cat(val_pred), torch.cat(val_true)\n",
    "                \n",
    "            \n",
    "    def __train(self, X, Y) -> float:\n",
    "        self.optimizer.zero_grad()\n",
    "        if self.fp16:\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                outputs = self.model(X)\n",
    "                loss = self.loss_fn(outputs, Y)\n",
    "                \n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "\n",
    "        else:\n",
    "            outputs = self.model(X)\n",
    "            loss = self.loss_fn(outputs, Y)    \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        if self.metric:\n",
    "            self.metric(outputs.sigmoid(), Y.int())\n",
    "            \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eb8a6bfe-3f63-4fcb-9bc9-41f3efa2cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    EmbedDataset(\n",
    "        x=Xtrain, \n",
    "        y=Ytrain, \n",
    "        embeds=Xembs,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d2565cb2-f3b2-460b-851e-dd0bd9a9ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valLoader = torch.utils.data.DataLoader(\n",
    "    TestDataset(\n",
    "        x=Xval, \n",
    "        y=Yval, \n",
    "        embeds=Xembs,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "643c68e6-f9c7-4a97-879b-62e887a85829",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoader = torch.utils.data.DataLoader(\n",
    "    TestDataset(\n",
    "        x=Xtest, \n",
    "        y=Ytest, \n",
    "        embeds=Xembs,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ff882e6c-a0e5-4819-b296-46b750f52bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = Model(EMBED_DIM, d=[32, 32])\n",
    "trainer = Trainer(\n",
    "    model=model.cuda(),\n",
    "    stop_batch=10_000/2048,\n",
    "    metric=torchmetrics.AUROC(),\n",
    "    loss_fn=nn.BCEWithLogitsLoss(reduce=True),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=3e-4),\n",
    ")\n",
    "\n",
    "acc = torchmetrics.Accuracy()\n",
    "auc = torchmetrics.AUROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "022ec494-041d-4974-82bb-21e498a9f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'InceptionResnetV1 vggface2 pca 64'\n",
    "board_name = name + datetime.datetime.now().strftime(\"%Y.%m.%d - %H-%M-%S\")\n",
    "\n",
    "log_dir = f\"logs/fit/{board_name}\"\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0e29411c-1ad0-4713-92a8-a118a7c5d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wait = 0\n",
    "    patience = 50\n",
    "    \n",
    "    epoch = 0\n",
    "    best_loss = -np.inf\n",
    "    while wait < patience:\n",
    "        train_loss = trainer.train(trainLoader, epoch)\n",
    "\n",
    "        val_pred, val_true = trainer.val(valLoader)\n",
    "        metrics = {\n",
    "            'AUC': auc(val_pred.sigmoid(), val_true.int()),\n",
    "            'ACC': acc(val_pred.sigmoid(), val_true.int()),\n",
    "        }\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('AUC/train', trainer.metric.compute(), epoch)\n",
    "        writer.add_scalar('AUC/val', metrics['AUC'], epoch)\n",
    "        writer.add_scalar('ACC/val', metrics['ACC'], epoch)\n",
    "\n",
    "\n",
    "        wait+=1\n",
    "        epoch+=1\n",
    "        if metrics['AUC'] > best_loss:\n",
    "            checkpoint = trainer.checkpoint()\n",
    "            torch.save(checkpoint, f'models/w/{name}.torch')\n",
    "            best_loss = metrics['AUC']\n",
    "            wait = 0\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "00dae26d-de34-4442-8598-48ccb0ffc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred, test_true = trainer.val(testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1caa10d7-0025-4bc4-94aa-3d6b879aec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "edf0f38c-4054-434c-9154-38dc5c513f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "08ec1aa5-7622-4f86-9dd4-5b20e7699d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca, open(\"models/pca.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65196a-2e87-4c0c-bdb6-2ec4987e25c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for conf, label, pic in zip(val_pred, val_true, Xval):\n",
    "    print(conf.sigmoid(), label)\n",
    "    img = Image.open(pic)\n",
    "    plt.imshow(img)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
