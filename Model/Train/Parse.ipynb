{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af977aef-c7e0-4164-9652-715c14fa5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from contextlib import suppress\n",
    "\n",
    "import torch\n",
    "from lxml import html\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "# Import from parent directory\n",
    "sys.path.insert(0, \"C:/Projects/DateMatching\") \n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85092147-c7e2-4aa7-a7bb-67d125bfb1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(body: html.HtmlElement) -> str|None:\n",
    "    with suppress(Exception):\n",
    "        name = body.find_class('from_name')[0].text\n",
    "        name = name.replace('\\n', '').strip()\n",
    "        return name\n",
    "\n",
    "def get_photo(body: html.HtmlElement) -> str|None:\n",
    "    with suppress(Exception):\n",
    "        div = body.find_class('media_wrap')[0]\n",
    "        a = div.getchildren()[0]\n",
    "        photo = a.attrib['href']\n",
    "        return photo\n",
    "\n",
    "def get_text(body: html.HtmlElement, text=\"\") -> str|None:\n",
    "    with suppress(Exception):\n",
    "        div = body.find_class('text')[0]\n",
    "        for t in div.itertext():\n",
    "            text+= t\n",
    "            \n",
    "        text = text.replace('\\n', '', 2).strip()\n",
    "        return text\n",
    "\n",
    "def process_photo(photo_path:str, saved_path:str):\n",
    "    save_embs = True\n",
    "    if photo_path in embeder.path_id:\n",
    "        uid = embeder.path_id[photo_path]\n",
    "        if os.path.exists(f'{saved_path}/{uid}.png'):\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            save_embs = False\n",
    "\n",
    "    img = Image.open(photo_path)\n",
    "    _, e = photo_path.split('.')\n",
    "    if e.lower() == 'png':\n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "    img_cropped = mtcnn(img, save_path='tmp.png')\n",
    "    \n",
    "    # Check for founded face\n",
    "    if img_cropped is not None:\n",
    "        img_cropped = img_cropped.unsqueeze(0)\n",
    "    \n",
    "        if save_embs:\n",
    "            embs = [model(img_cropped) for model in embeds_models]\n",
    "            embeder[photo_path] = embs\n",
    "\n",
    "        uid = embeder.path_id[photo_path]\n",
    "        shutil.move('tmp.png', f'{saved_path}/{uid}.png')\n",
    "\n",
    "\n",
    "def procces_markup(src:str, dst:str):\n",
    "    if not src.endswith('/'):\n",
    "        src+= '/'\n",
    "        \n",
    "    if dst.endswith('/'):\n",
    "        dst = dst[:-1]\n",
    "        \n",
    "    for file in os.listdir(src):\n",
    "        photo_path = src + file\n",
    "        process_photo(photo_path, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df684f93-9f0c-4684-aef1-e6c864184add",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN()\n",
    "model1 = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "model2 = InceptionResnetV1(pretrained='casia-webface').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97afd91f-1dc2-43cc-bfcb-bd854b5590e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds_models = [model1, model2]\n",
    "embeder = utils.PhotoEmbedingStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c3c6d1-a02e-4c3f-9fc6-d994ae9682b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "for catalog in os.listdir('tg_data'):\n",
    "\n",
    "    for file in os.listdir('tg_data/' + catalog):\n",
    "        if '.html' in file:\n",
    "\n",
    "            with open(f\"tg_data/{catalog}/{file}\", \"r\", encoding='utf-8') as f:\n",
    "                _html = f.read()\n",
    "\n",
    "            tree = html.fromstring(_html)\n",
    "            history = tree.xpath(\"/html/body/div/div[2]/div\")[0]\n",
    "            history = history.find_class('message default clearfix')\n",
    "\n",
    "            for message in history:\n",
    "                body = message.find_class('body')[0]\n",
    "\n",
    "                photo = get_photo(body) \n",
    "                photo = f\"{catalog}/{photo}\" if photo else None\n",
    "                messages+= [{\n",
    "                    'name': get_name(body),\n",
    "                    'text': get_text(body),\n",
    "                    'photo': photo,\n",
    "                }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8de9eeae-9a41-41c5-a9af-919aa6d68d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_girls = 0\n",
    "for msg in messages:\n",
    "    if (msg['text'] and \n",
    "    (\"–ö–æ–º—É-—Ç–æ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å —Ç–≤–æ—è –∞–Ω–∫–µ—Ç–∞\" in msg['text'] or \n",
    "    \"–ï—Å—Ç—å –≤–∑–∞–∏–º–Ω–∞—è —Å–∏–º–ø–∞—Ç–∏—è\" in msg['text'])):\n",
    "        matched_girls +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70139766-1525-47d8-80df-2cb1e4794765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–æ–Ω—Ä–∞–≤–∏–ª—Å—è 543 –∂–µ–Ω—â–∏–Ω–∞–º\n"
     ]
    }
   ],
   "source": [
    "print(\"–ü–æ–Ω—Ä–∞–≤–∏–ª—Å—è {} –∂–µ–Ω—â–∏–Ω–∞–º\".format(matched_girls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4535b4b-3bcd-4eff-8933-69c089e407aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_likes = 0\n",
    "total_dislikes = 0\n",
    "for current, previous in zip(messages[1:], messages[:-1]):\n",
    "    if previous['photo'] and current['text']:\n",
    "        if current['text'] in ['üëç', '‚ù§Ô∏è', 'üíå', 'üíå / üìπ']:\n",
    "            total_likes += 1\n",
    "\n",
    "        if 'üëé' in current['text']:\n",
    "            total_dislikes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac4ae6a0-78fa-43ca-b2d9-f987a164e633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–Ω–≤–µ—Ä—Å–∏—è: 2.333175783096292 %\n"
     ]
    }
   ],
   "source": [
    "print('–ö–æ–Ω–≤–µ—Ä—Å–∏—è: {} %'.format(matched_girls*100/(total_dislikes + total_likes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebae6fc-40b9-4167-8e03-630e23a146ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for current, previous in zip(messages[1:], messages[:-1]):\n",
    "        if previous['photo']:\n",
    "            photo_path = 'tg_data/' + previous['photo']\n",
    "\n",
    "            if current['text'] in ['üíå', '‚ù§Ô∏è', 'üëç']:\n",
    "                saved_path = 'data/target'\n",
    "\n",
    "            elif current['text'] in ['üëé']:\n",
    "                saved_path = 'data/opposite'\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            process_photo(photo_path, saved_path)\n",
    "\n",
    "\n",
    "    procces_markup('markup/test_target',  \"data/test_target/\")\n",
    "    procces_markup('markup/test_opposite',  \"data/test_opposite/\")\n",
    "    procces_markup('markup/target',  \"data/markup_target/\")\n",
    "    procces_markup('markup/opposite',  \"data/markup_opposite/\")\n",
    "\n",
    "embeder.save('models/emb storage.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
