{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1835cc1-4b29-4abe-b750-f91d032e0521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2df4bdb-c839-4d2d-814a-33672f21aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "parentdir = \"C:\\Projects\\DateMatching\"\n",
    "sys.path.insert(0, parentdir) \n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8125de3b-a43f-4e28-afc4-36f574491741",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeder = utils.PhotoEmbedingStorage('../Models/emb storage.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd9bf25-bb9c-41b2-9cd7-5c47d7291b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity tensor([[0.7698]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeder[13550]\n",
    "emb2 = embeder[2169]\n",
    "print('similarity', emb1 @ emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0579a5-4e1d-42eb-bdf5-1ad10d832e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity tensor([[0.6263]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeder[13543]\n",
    "emb2 = embeder[13544]\n",
    "print('similarity', emb1 @ emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9f9363-5555-4583-921c-eb049330f442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity tensor([[0.5527]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeder[13546]\n",
    "emb2 = embeder[13547]\n",
    "print('similarity', emb1 @ emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7615d610-e5e1-4102-9c8e-96bf36da4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity tensor([[0.3056]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeder[13543]\n",
    "emb2 = embeder[13550]\n",
    "print('similarity', emb1 @ emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7e978a-cfbd-45f9-91fc-783851acb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EMBED_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d58d66-f2b2-4c55-a9ba-88a3c0308560",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_opposite = []\n",
    "files_target = []\n",
    "\n",
    "path = \"data/markup_opposite/\"\n",
    "files_opposite += [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "    \n",
    "path =  \"data/markup_target/\"\n",
    "files_target += [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "\n",
    "path = \"data/opposite/\"\n",
    "files_opposite += [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "\n",
    "path =  \"data/target/\"\n",
    "files_target += [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "\n",
    "files_opposite = np.array(files_opposite)\n",
    "files_target = np.array(files_target)\n",
    "\n",
    "y_opposite = np.zeros_like(files_opposite, dtype='float32')\n",
    "y_target = np.ones_like(files_target, dtype='float32')\n",
    "\n",
    "X = np.concatenate([files_opposite, files_target])\n",
    "Y = np.concatenate([y_opposite, y_target])\n",
    "\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba82b8d1-6db5-43e9-96bf-66ffb9eb29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = []\n",
    "Ytest = []\n",
    "\n",
    "path = \"data/test_target/\"\n",
    "ldir = [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "Xtest+= ldir\n",
    "Ytest+= [1. for _ in ldir]\n",
    "    \n",
    "path = \"data/test_opposite/\"\n",
    "ldir = [int(f.split('.')[0]) for f in os.listdir(path)]\n",
    "Xtest+= ldir\n",
    "Ytest+= [0. for _ in ldir]\n",
    "\n",
    "Xtest = np.array(Xtest)\n",
    "Ytest = np.array(Ytest, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb0ef22-08d5-4ee7-a39d-2db39507c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.concatenate([embeder[int(xid)] for xid in Xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c3939b-136d-4f31-a6f4-c1540645c433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=32)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=EMBED_DIM)\n",
    "pca.fit(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ec1aa5-7622-4f86-9dd4-5b20e7699d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca, open(\"../Models/pca.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8a6bfe-3f63-4fcb-9bc9-41f3efa2cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    utils.EmbedDataset(\n",
    "        x=Xtrain, \n",
    "        y=Ytrain, \n",
    "        embeder=embeder,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2565cb2-f3b2-460b-851e-dd0bd9a9ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valLoader = torch.utils.data.DataLoader(\n",
    "    utils.TestDataset(\n",
    "        x=Xval, \n",
    "        y=Yval, \n",
    "        embeder=embeder,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "643c68e6-f9c7-4a97-879b-62e887a85829",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoader = torch.utils.data.DataLoader(\n",
    "    utils.TestDataset(\n",
    "        x=Xtest, \n",
    "        y=Ytest, \n",
    "        embeder=embeder,\n",
    "        decompositor=pca.transform), \n",
    "    batch_size=2048, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff882e6c-a0e5-4819-b296-46b750f52bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = utils.Model(EMBED_DIM, d=[64, 64])\n",
    "trainer = utils.Trainer(\n",
    "    model=model.cuda(),\n",
    "    stop_batch=10_000/2048,\n",
    "    metric=torchmetrics.AUROC(),\n",
    "    loss_fn=nn.BCEWithLogitsLoss(reduce=True),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=3e-4),\n",
    ")\n",
    "\n",
    "acc = torchmetrics.Accuracy()\n",
    "auc = torchmetrics.AUROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a23061-f7d0-4005-9a1c-6a9eac47c6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Linear: 2-1                       2,112\n",
      "|    └─Dropout: 2-2                      --\n",
      "|    └─GELU: 2-3                         --\n",
      "|    └─Linear: 2-4                       4,160\n",
      "|    └─Dropout: 2-5                      --\n",
      "|    └─GELU: 2-6                         --\n",
      "|    └─Linear: 2-7                       65\n",
      "|    └─Dropout: 2-8                      --\n",
      "=================================================================\n",
      "Total params: 6,337\n",
      "Trainable params: 6,337\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "022ec494-041d-4974-82bb-21e498a9f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'InceptionResnetV1 vggface2 pca 32 '\n",
    "board_name = name + datetime.datetime.now().strftime(\"%Y.%m.%d - %H-%M-%S\")\n",
    "\n",
    "log_dir = f\"logs/fit/{board_name}\"\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e29411c-1ad0-4713-92a8-a118a7c5d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wait = 0\n",
    "    patience = 50\n",
    "    \n",
    "    epoch = 0\n",
    "    best_loss = -np.inf\n",
    "    while wait < patience:\n",
    "        train_loss = trainer.train(trainLoader, epoch)\n",
    "\n",
    "        val_pred, val_true = trainer.val(valLoader)\n",
    "        metrics = {\n",
    "            'AUC': auc(val_pred.sigmoid(), val_true.int()),\n",
    "            'ACC': acc(val_pred.sigmoid(), val_true.int()),\n",
    "        }\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('AUC/train', trainer.metric.compute(), epoch)\n",
    "        writer.add_scalar('AUC/val', metrics['AUC'], epoch)\n",
    "        writer.add_scalar('ACC/val', metrics['ACC'], epoch)\n",
    "\n",
    "\n",
    "        wait+=1\n",
    "        epoch+=1\n",
    "        if metrics['AUC'] > best_loss:\n",
    "            checkpoint = trainer.checkpoint()\n",
    "            torch.save(checkpoint, f'../Models/w/{name}.torch')\n",
    "            best_loss = metrics['AUC']\n",
    "            wait = 0\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22688115-7a71-40df-8250-9bd50edb57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'../Models/w/{name}.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27a02a50-581b-41e2-99ce-e95b0a7688ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InceptionResnetV1 vggface2 pca 32'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f30a6965-c063-4421-9329-b0b09796743a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9341442-f944-4061-8302-a55789c24c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13543, 13544, 13545, 13546, 13547, 13550,  2169])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00dae26d-de34-4442-8598-48ccb0ffc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred, test_true = trainer.val(testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d4ca4f7-6fe2-4aeb-bfc1-2b4fde55f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: tensor(0.)\n",
      "ACC: tensor(0.4286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print('AUC:', auc(test_pred.sigmoid(), test_true.int()))\n",
    "print('ACC:', acc(test_pred.sigmoid(), test_true.int()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "184c8037-2ab0-41fb-af1d-9ca9566c16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, f'../Models/w/prod.torch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
